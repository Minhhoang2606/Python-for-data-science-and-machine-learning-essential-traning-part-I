{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df7e8e9c",
   "metadata": {},
   "source": [
    "## Data Importing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eb3d2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "   OrderID Customer  Amount        Date\n",
      "0      101    Alice   250.0  2023/01/15\n",
      "1      102      Bob   300.0  2023-01-16\n",
      "2      103  Charlie     NaN  2023-01-16\n",
      "3      103  Charlie     NaN  2023-01-16\n",
      "4      104      Eve   400.0  2023/01/17\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating an artificial dataset\n",
    "data = {\n",
    "    'OrderID': [101, 102, 103, 103, 104],\n",
    "    'Customer': ['Alice', 'Bob', 'Charlie', 'Charlie', 'Eve'],\n",
    "    'Amount': [250, 300, None, None, 400],\n",
    "    'Date': ['2023/01/15', '2023-01-16', '2023-01-16', '2023-01-16', '2023/01/17']\n",
    "}\n",
    "\n",
    "# Converting it to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the raw data\n",
    "print(\"Original Data:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c5a5930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Removing Duplicates:\n",
      "   OrderID Customer  Amount        Date\n",
      "0      101    Alice   250.0  2023/01/15\n",
      "1      102      Bob   300.0  2023-01-16\n",
      "2      103  Charlie     NaN  2023-01-16\n",
      "4      104      Eve   400.0  2023/01/17\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(\"\\nAfter Removing Duplicates:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc78d0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Removing Out-of-Range Values:\n",
      "   OrderID Customer  Amount        Date\n",
      "0      101    Alice   250.0  2023/01/15\n",
      "1      102      Bob   300.0  2023-01-16\n",
      "4      104      Eve   400.0  2023/01/17\n"
     ]
    }
   ],
   "source": [
    "# Remove rows where 'Amount' is less than zero\n",
    "df = df[df['Amount'] >= 0]\n",
    "\n",
    "print(\"\\nAfter Removing Out-of-Range Values:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61ab6eb",
   "metadata": {},
   "source": [
    "## Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "097565ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      "      Name   Age   Salary         City\n",
      "0    Alice  25.0  50000.0     New York\n",
      "1      Bob   NaN  60000.0          NaN\n",
      "2  Charlie  30.0      NaN  Los Angeles\n",
      "3    David   NaN  40000.0      Chicago\n",
      "4      Eve  40.0  70000.0     New York\n"
     ]
    }
   ],
   "source": [
    "# Creating an artificial dataset with missing values\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'Age': [25, np.nan, 30, np.nan, 40],\n",
    "    'Salary': [50000, 60000, np.nan, 40000, 70000],\n",
    "    'City': ['New York', np.nan, 'Los Angeles', 'Chicago', 'New York']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the dataset\n",
    "print(\"Original Dataset:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a03e8a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values in Each Column:\n",
      "Name      0\n",
      "Age       2\n",
      "Salary    1\n",
      "City      1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in each column\n",
    "print(\"\\nMissing Values in Each Column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "791d854d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset After Dropping Rows with Missing Values:\n",
      "    Name   Age   Salary      City\n",
      "0  Alice  25.0  50000.0  New York\n",
      "4    Eve  40.0  70000.0  New York\n",
      "\n",
      "Dataset After Dropping Columns with Missing Values:\n",
      "      Name\n",
      "0    Alice\n",
      "1      Bob\n",
      "2  Charlie\n",
      "3    David\n",
      "4      Eve\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing values\n",
    "df_dropped_rows = df.dropna()\n",
    "\n",
    "# Drop columns with missing values\n",
    "df_dropped_cols = df.dropna(axis=1)\n",
    "\n",
    "print(\"\\nDataset After Dropping Rows with Missing Values:\")\n",
    "print(df_dropped_rows)\n",
    "\n",
    "print(\"\\nDataset After Dropping Columns with Missing Values:\")\n",
    "print(df_dropped_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ad20a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Filling Missing 'City' Values:\n",
      "      Name   Age   Salary         City\n",
      "0    Alice  25.0  50000.0     New York\n",
      "1      Bob   NaN  60000.0      Unknown\n",
      "2  Charlie  30.0      NaN  Los Angeles\n",
      "3    David   NaN  40000.0      Chicago\n",
      "4      Eve  40.0  70000.0     New York\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values in 'City' with 'Unknown'\n",
    "df['City'] = df['City'].fillna('Unknown')\n",
    "\n",
    "print(\"\\nAfter Filling Missing 'City' Values:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af687c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Filling Missing 'Age' and 'Salary' Values:\n",
      "      Name        Age   Salary         City\n",
      "0    Alice  25.000000  50000.0     New York\n",
      "1      Bob  31.666667  60000.0      Unknown\n",
      "2  Charlie  30.000000  55000.0  Los Angeles\n",
      "3    David  31.666667  40000.0      Chicago\n",
      "4      Eve  40.000000  70000.0     New York\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values in 'Age' with the mean\n",
    "df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "\n",
    "# Fill missing values in 'Salary' with the median\n",
    "df['Salary'] = df['Salary'].fillna(df['Salary'].median())\n",
    "\n",
    "print(\"\\nAfter Filling Missing 'Age' and 'Salary' Values:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c67535b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Interpolating 'Age':\n",
      "      Name        Age   Salary         City\n",
      "0    Alice  25.000000  50000.0     New York\n",
      "1      Bob  31.666667  60000.0      Unknown\n",
      "2  Charlie  30.000000  55000.0  Los Angeles\n",
      "3    David  31.666667  40000.0      Chicago\n",
      "4      Eve  40.000000  70000.0     New York\n"
     ]
    }
   ],
   "source": [
    "# Interpolate missing values linearly\n",
    "df['Age'] = df['Age'].interpolate()\n",
    "\n",
    "print(\"\\nAfter Interpolating 'Age':\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9d12a0",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e2963eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      "      Name  Math_Score  Science_Score\n",
      "0    Alice          50             30\n",
      "1      Bob          80             85\n",
      "2  Charlie          70             75\n",
      "3    David          60             95\n",
      "4      Eve          90             40\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Creating an artificial dataset\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'Math_Score': [50, 80, 70, 60, 90],\n",
    "    'Science_Score': [30, 85, 75, 95, 40]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original Dataset:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f810bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Normalization:\n",
      "      Name  Math_Score  Science_Score\n",
      "0    Alice        0.00       0.000000\n",
      "1      Bob        0.75       0.846154\n",
      "2  Charlie        0.50       0.692308\n",
      "3    David        0.25       1.000000\n",
      "4      Eve        1.00       0.153846\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply normalization\n",
    "df[['Math_Score', 'Science_Score']] = scaler.fit_transform(df[['Math_Score', 'Science_Score']])\n",
    "\n",
    "print(\"\\nAfter Normalization:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b67fa2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Standardization:\n",
      "      Name  Math_Score  Science_Score\n",
      "0    Alice   -1.414214      -1.372813\n",
      "1      Bob    0.707107       0.784465\n",
      "2  Charlie    0.000000       0.392232\n",
      "3    David   -0.707107       1.176697\n",
      "4      Eve    1.414214      -0.980581\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply standardization\n",
    "df[['Math_Score', 'Science_Score']] = scaler.fit_transform(df[['Math_Score', 'Science_Score']])\n",
    "\n",
    "print(\"\\nAfter Standardization:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9822a931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Array:\n",
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]]\n",
      "\n",
      "Reshaped Array:\n",
      "[[ 1  2  3  4  5  6]\n",
      " [ 7  8  9 10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Creating a NumPy array\n",
    "array = np.arange(1, 13).reshape(4, 3)\n",
    "print(\"\\nOriginal Array:\")\n",
    "print(array)\n",
    "\n",
    "# Reshape to a different dimension\n",
    "reshaped_array = array.reshape(2, 6)\n",
    "print(\"\\nReshaped Array:\")\n",
    "print(reshaped_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "474ff415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After One-Hot Encoding:\n",
      "      Name  City_Chicago  City_LA  City_NY\n",
      "0    Alice         False    False     True\n",
      "1      Bob         False     True    False\n",
      "2  Charlie         False    False     True\n",
      "3    David          True    False    False\n",
      "4      Eve         False     True    False\n"
     ]
    }
   ],
   "source": [
    "# Creating a dataset with categorical data\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'], 'City': ['NY', 'LA', 'NY', 'Chicago', 'LA']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply one-hot encoding\n",
    "df_encoded = pd.get_dummies(df, columns=['City'])\n",
    "\n",
    "print(\"\\nAfter One-Hot Encoding:\")\n",
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b29d2fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset Using iloc:\n",
      "      Product  Price\n",
      "0      Laptop   1000\n",
      "1  Smartphone    800\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating an artificial dataset\n",
    "data = {\n",
    "    'Product': ['Laptop', 'Smartphone', 'Tablet', 'Monitor', 'Keyboard'],\n",
    "    'Price': [1000, 800, 300, 200, 50],\n",
    "    'Units_Sold': [50, 120, 70, 30, 200]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Access the first two rows and first two columns\n",
    "subset = df.iloc[:2, :2]\n",
    "\n",
    "print(\"Subset Using iloc:\")\n",
    "print(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d44b6432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subset Using loc:\n",
      "      Product  Price\n",
      "0      Laptop   1000\n",
      "1  Smartphone    800\n",
      "2      Tablet    300\n"
     ]
    }
   ],
   "source": [
    "# Access rows by index label and specific columns\n",
    "subset = df.loc[0:2, ['Product', 'Price']]\n",
    "\n",
    "print(\"\\nSubset Using loc:\")\n",
    "print(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63c5930e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered Data (Price > 300):\n",
      "      Product  Price  Units_Sold\n",
      "0      Laptop   1000          50\n",
      "1  Smartphone    800         120\n"
     ]
    }
   ],
   "source": [
    "# Filter products with a price greater than $300\n",
    "filtered_df = df[df['Price'] > 300]\n",
    "\n",
    "print(\"\\nFiltered Data (Price > 300):\")\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d35717bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered Data (Price > 300 and Units Sold > 50):\n",
      "      Product  Price  Units_Sold\n",
      "1  Smartphone    800         120\n"
     ]
    }
   ],
   "source": [
    "# Filter products priced above $300 and with more than 50 units sold\n",
    "filtered_df = df[(df['Price'] > 300) & (df['Units_Sold'] > 50)]\n",
    "\n",
    "print(\"\\nFiltered Data (Price > 300 and Units Sold > 50):\")\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8271b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subset Using Fancy Indexing:\n",
      "   Price  Units_Sold\n",
      "0   1000          50\n",
      "2    300          70\n"
     ]
    }
   ],
   "source": [
    "# Fancy indexing with arrays\n",
    "rows = [0, 2]  # First and third rows\n",
    "columns = ['Price', 'Units_Sold']  # Specific columns\n",
    "subset = df.loc[rows, columns]\n",
    "\n",
    "print(\"\\nSubset Using Fancy Indexing:\")\n",
    "print(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7461a6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sliced Data (Rows 1 to 3):\n",
      "      Product  Price  Units_Sold\n",
      "1  Smartphone    800         120\n",
      "2      Tablet    300          70\n",
      "3     Monitor    200          30\n"
     ]
    }
   ],
   "source": [
    "# Slicing rows 1 to 3 (exclusive) and all columns\n",
    "subset = df.iloc[1:4, :]\n",
    "\n",
    "print(\"\\nSliced Data (Rows 1 to 3):\")\n",
    "print(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dac57f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered Data (Product Contains 'phone'):\n",
      "      Product  Price  Units_Sold\n",
      "1  Smartphone    800         120\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where 'Product' contains 'phone'\n",
    "filtered_df = df[df['Product'].str.contains('phone', case=False)]\n",
    "\n",
    "print(\"\\nFiltered Data (Product Contains 'phone'):\")\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db48d28",
   "metadata": {},
   "source": [
    "## Concatenating and Transforming Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a92520b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row-wise Concatenated Dataset:\n",
      "   CustomerID     Name\n",
      "0           1    Alice\n",
      "1           2      Bob\n",
      "2           3  Charlie\n",
      "3           4    David\n",
      "4           5      Eve\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating two datasets\n",
    "data1 = {\n",
    "    'CustomerID': [1, 2, 3],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie']\n",
    "}\n",
    "data2 = {\n",
    "    'CustomerID': [4, 5],\n",
    "    'Name': ['David', 'Eve']\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Concatenating datasets row-wise\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "print(\"Row-wise Concatenated Dataset:\")\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd3737f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column-wise Concatenated Dataset:\n",
      "   CustomerID     Name  Purchase_Amount\n",
      "0           1    Alice              100\n",
      "1           2      Bob              200\n",
      "2           3  Charlie              150\n"
     ]
    }
   ],
   "source": [
    "# Creating datasets\n",
    "data1 = {\n",
    "    'CustomerID': [1, 2, 3],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie']\n",
    "}\n",
    "data2 = {\n",
    "    'Purchase_Amount': [100, 200, 150]\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Concatenating datasets column-wise\n",
    "combined_df = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "print(\"\\nColumn-wise Concatenated Dataset:\")\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "588b9c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset After Dropping Column 'Name':\n",
      "   CustomerID  Purchase_Amount\n",
      "0           1              100\n",
      "1           2              200\n",
      "2           3              150\n"
     ]
    }
   ],
   "source": [
    "# Dropping a column\n",
    "df = combined_df.drop(columns=['Name'])\n",
    "\n",
    "print(\"\\nDataset After Dropping Column 'Name':\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "326aa451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset After Adding a New Column:\n",
      "   CustomerID  Purchase_Amount Category\n",
      "0           1              100      Low\n",
      "1           2              200     High\n",
      "2           3              150   Medium\n"
     ]
    }
   ],
   "source": [
    "# Adding a new column for purchase categories\n",
    "df['Category'] = ['Low', 'High', 'Medium']\n",
    "\n",
    "print(\"\\nDataset After Adding a New Column:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sorted Dataset:\n",
      "   CustomerID  Purchase_Amount Category\n",
      "1           2              200     High\n",
      "2           3              150   Medium\n",
      "0           1              100      Low\n"
     ]
    }
   ],
   "source": [
    "# Sorting by purchase amount in descending order\n",
    "sorted_df = df.sort_values(by='Purchase_Amount', ascending=False)\n",
    "\n",
    "print(\"\\nSorted Dataset:\")\n",
    "print(sorted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce9a4a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pivoted Dataset:\n",
      "PurchaseType  In-Store  Online\n",
      "CustomerID                    \n",
      "1                   50      50\n",
      "2                  100     100\n"
     ]
    }
   ],
   "source": [
    "# Creating a dataset for reshaping\n",
    "data = {\n",
    "    'CustomerID': [1, 1, 2, 2],\n",
    "    'PurchaseType': ['Online', 'In-Store', 'Online', 'In-Store'],\n",
    "    'Amount': [50, 50, 100, 100]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Pivoting data to create a summary table\n",
    "pivoted_df = df.pivot(index='CustomerID', columns='PurchaseType', values='Amount')\n",
    "\n",
    "print(\"\\nPivoted Dataset:\")\n",
    "print(pivoted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cab49f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned Dataset After Removing Duplicates:\n",
      "   CustomerID  Amount\n",
      "0           1     100\n",
      "1           2     200\n",
      "3           3     150\n"
     ]
    }
   ],
   "source": [
    "# Adding duplicate rows for demonstration\n",
    "df1 = pd.DataFrame({'CustomerID': [1, 2], 'Amount': [100, 200]})\n",
    "df2 = pd.DataFrame({'CustomerID': [2, 3], 'Amount': [200, 150]})\n",
    "\n",
    "# Row-wise concatenation\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Removing duplicates\n",
    "cleaned_df = combined_df.drop_duplicates()\n",
    "\n",
    "print(\"\\nCleaned Dataset After Removing Duplicates:\")\n",
    "print(cleaned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f880de9",
   "metadata": {},
   "source": [
    "## Logging and Data Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "debb016f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Name    3 non-null      object\n",
      " 1   Age     3 non-null      int64 \n",
      " 2   City    3 non-null      object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 204.0+ bytes\n",
      "None\n",
      "\n",
      "Statistical Summary:\n",
      "         Name   Age      City\n",
      "count       3   3.0         3\n",
      "unique      3   NaN         3\n",
      "top     Alice   NaN  New York\n",
      "freq        1   NaN         1\n",
      "mean      NaN  30.0       NaN\n",
      "std       NaN   5.0       NaN\n",
      "min       NaN  25.0       NaN\n",
      "25%       NaN  27.5       NaN\n",
      "50%       NaN  30.0       NaN\n",
      "75%       NaN  32.5       NaN\n",
      "max       NaN  35.0       NaN\n"
     ]
    }
   ],
   "source": [
    "# Creating a sample dataset\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Log metadata\n",
    "print(\"Dataset Information:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eaa70bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metadata to a log file\n",
    "with open(\"data_log.txt\", \"w\") as log_file:\n",
    "    df.info(buf=log_file)\n",
    "    log_file.write(\"\\n\")\n",
    "    log_file.write(str(df.describe(include='all')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61bc56b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Backup created at: data_backup.csv\n"
     ]
    }
   ],
   "source": [
    "# Save a backup of the dataset\n",
    "backup_path = \"data_backup.csv\"\n",
    "df.to_csv(backup_path, index=False)\n",
    "\n",
    "print(\"\\nBackup created at:\", backup_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d02636",
   "metadata": {},
   "source": [
    "## Practical Applications and Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e40f91f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mazda RX4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.620</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mazda RX4 Wag</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Datsun 710</td>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.320</td>\n",
       "      <td>18.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hornet 4 Drive</td>\n",
       "      <td>21.4</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hornet Sportabout</td>\n",
       "      <td>18.7</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0   mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  \\\n",
       "0          Mazda RX4  21.0    6  160.0  110  3.90  2.620  16.46   0   1     4   \n",
       "1      Mazda RX4 Wag  21.0    6  160.0  110  3.90  2.875  17.02   0   1     4   \n",
       "2         Datsun 710  22.8    4  108.0   93  3.85  2.320  18.61   1   1     4   \n",
       "3     Hornet 4 Drive  21.4    6  258.0  110  3.08  3.215  19.44   1   0     3   \n",
       "4  Hornet Sportabout  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3   \n",
       "\n",
       "   carb  \n",
       "0     4  \n",
       "1     4  \n",
       "2     1  \n",
       "3     1  \n",
       "4     2  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "mtcars_df = pd.read_csv(R'..\\data\\mtcars.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "mtcars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1660dcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cars with MPG > 25:\n",
      "        Unnamed: 0   mpg\n",
      "17        Fiat 128  32.4\n",
      "18     Honda Civic  30.4\n",
      "19  Toyota Corolla  33.9\n",
      "25       Fiat X1-9  27.3\n",
      "26   Porsche 914-2  26.0\n",
      "27    Lotus Europa  30.4\n"
     ]
    }
   ],
   "source": [
    "# Filter cars with mpg > 25\n",
    "high_mpg_cars = mtcars_df[mtcars_df['mpg'] > 25]\n",
    "\n",
    "print(\"Cars with MPG > 25:\")\n",
    "print(high_mpg_cars[['Unnamed: 0', 'mpg']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "defa4cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Dataset:\n",
      "          Unnamed: 0   mpg    Price\n",
      "0          Mazda RX4  21.0  15000.0\n",
      "1      Mazda RX4 Wag  21.0      NaN\n",
      "2         Datsun 710  22.8  12000.0\n",
      "3     Hornet 4 Drive  21.4      NaN\n",
      "4  Hornet Sportabout  18.7      NaN\n"
     ]
    }
   ],
   "source": [
    "# Creating a car prices dataset\n",
    "prices_data = {\n",
    "    'Unnamed: 0': ['Mazda RX4', 'Datsun 710', 'Toyota Corolla'],\n",
    "    'Price': [15000, 12000, 18000]\n",
    "}\n",
    "\n",
    "prices_df = pd.DataFrame(prices_data)\n",
    "\n",
    "# Merging the mtcars dataset with the prices dataset\n",
    "merged_df = pd.merge(mtcars_df, prices_df, on='Unnamed: 0', how='left')\n",
    "\n",
    "print(\"Merged Dataset:\")\n",
    "print(merged_df[['Unnamed: 0', 'mpg', 'Price']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5f765bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with New Feature (Power-to-Weight Ratio):\n",
      "          Unnamed: 0   hp     wt  power_to_weight_ratio\n",
      "0          Mazda RX4  110  2.620              41.984733\n",
      "1      Mazda RX4 Wag  110  2.875              38.260870\n",
      "2         Datsun 710   93  2.320              40.086207\n",
      "3     Hornet 4 Drive  110  3.215              34.214619\n",
      "4  Hornet Sportabout  175  3.440              50.872093\n"
     ]
    }
   ],
   "source": [
    "# Add a power-to-weight ratio column\n",
    "mtcars_df['power_to_weight_ratio'] = mtcars_df['hp'] / mtcars_df['wt']\n",
    "\n",
    "print(\"Dataset with New Feature (Power-to-Weight Ratio):\")\n",
    "print(mtcars_df[['Unnamed: 0', 'hp', 'wt', 'power_to_weight_ratio']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b813c1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MPG by Number of Cylinders:\n",
      "   cyl        mpg\n",
      "0    4  26.663636\n",
      "1    6  19.742857\n",
      "2    8  15.100000\n"
     ]
    }
   ],
   "source": [
    "# Group cars by the number of cylinders and calculate average mpg\n",
    "avg_mpg_by_cyl = mtcars_df.groupby('cyl')['mpg'].mean().reset_index()\n",
    "\n",
    "print(\"Average MPG by Number of Cylinders:\")\n",
    "print(avg_mpg_by_cyl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
